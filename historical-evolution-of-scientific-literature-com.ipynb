{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":83735,"databundleVersionId":9881586,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üìò Historical Evolution of AI Research - A Decade-Wise Comparative Analysis\r\n\r\n---\r\n\r\nThis notebook is part of the **Gemini 1.5 Long Context competition**, demonstrating how the model's long context window enables the analysis of a large set of scientific literature spanning decades. The goal is to uncover trends, paradigm shifts, and developments within the field of Artificial Intelligence (AI) by analyzing thousands of research papers, books, and conference proceedings from the 1970s to today.\r\n\r\n---\r\n\r\n## üìù Introduction\r\n\r\nThe **Gemini 1.5 model**, with its breakthrough large context window of **2 million tokens**, enables the processing of vast amounts of data in a single context. In this project, we leverage this capability to analyze the evolution of scientific literature in AI over the past 50 years. This analysis covers how research trends, terminologies, and paradigms have shifted from one decade to the next, culminating in the current state of the field.\r\n\r\n### Why this is important:\r\n\r\n- **Rapid Evolution**: Scientific fields evolve rapidly, and understanding the historical context is crucial for predicting future trends.\r\n- **Trend Analysis**: By analyzing research trends, we can better identify emerging technologies, shifting methodologies, and influential papers that have shaped AI's progress.\r\n- **Long Context Window**: Gemini's long context window allows us to analyze the entire history of AI research in one continuous process, preserving important contextual connections between papers published across decades.","metadata":{}},{"cell_type":"code","source":"!pip install arxiv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-22T07:23:15.558095Z","iopub.execute_input":"2024-10-22T07:23:15.558523Z","iopub.status.idle":"2024-10-22T07:24:36.377238Z","shell.execute_reply.started":"2024-10-22T07:23:15.558476Z","shell.execute_reply":"2024-10-22T07:24:36.375975Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x793d6578d750>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/arxiv/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x793d6578d900>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/arxiv/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x793d6578dea0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/arxiv/\u001b[0m\u001b[33m\n\u001b[0m^C\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Import all necessary libraries here.\nimport arxiv\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-22T07:24:36.379589Z","iopub.execute_input":"2024-10-22T07:24:36.380026Z","iopub.status.idle":"2024-10-22T07:24:36.409494Z","shell.execute_reply.started":"2024-10-22T07:24:36.379984Z","shell.execute_reply":"2024-10-22T07:24:36.408036Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import all necessary libraries here.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01marxiv\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'arxiv'"],"ename":"ModuleNotFoundError","evalue":"No module named 'arxiv'","output_type":"error"}],"execution_count":3},{"cell_type":"markdown","source":"## üìä Dataset Overview\nThe dataset used in this analysis contains a comprehensive collection of AI research papers spanning over 50 years. Sourced from arXiv.org and NeurIPS conference proceedings, it includes metadata such as titles, authors, abstracts, publication dates, and key terms. This structured information allows us to analyze the evolution of AI research and track paradigm shifts within the field.\n\n### Why this dataset is valuable:\n- **Comprehensive Coverage**: The dataset spans multiple decades, capturing the progression of AI research from its early stages to the present.\n- **Insightful Metadata**: With detailed abstracts, keywords, and publication dates, the dataset provides rich context for understanding research trends and identifying influential papers.\n- **Enabling Long-Context Analysis**: The structured data aligns perfectly with Gemini's capability to handle large context windows, enabling a holistic view of AI's development and preserving connections across decades of research.\n\nThis dataset is essential for identifying patterns, understanding the evolution of terminology, and uncovering the emerging technologies that shape the future of AI.","metadata":{},"attachments":{"7ee2cbe6-5c4d-4def-bafa-341ffb8e6423.png":{"image/png":"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"}}},{"cell_type":"code","source":"# Query for AI-related papers from the arXiv API\nsearch_query = 'cat:cs.AI OR cat:stat.ML OR cat:cs.LG'\nsearch = arxiv.Search(\n    query=search_query,\n    max_results=1000,\n    sort_by=arxiv.SortCriterion.SubmittedDate\n)\n\n# Fetch and store paper metadata\npapers = []\nfor result in search.results():\n    papers.append({\n        'title': result.title,\n        'authors': [author.name for author in result.authors],\n        'abstract': result.summary,\n        'published': result.published,\n        'categories': result.categories,\n        'pdf_url': result.pdf_url\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-22T07:24:36.410597Z","iopub.status.idle":"2024-10-22T07:24:36.411005Z","shell.execute_reply.started":"2024-10-22T07:24:36.410818Z","shell.execute_reply":"2024-10-22T07:24:36.410838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# After fetching the papers, save the metadata to a CSV file for easier use in Kaggle working directory (/kaggle/working)\ndf = pd.DataFrame(papers)\ndf.to_csv('/kaggle/working/arxiv_ai_papers.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-22T07:24:36.412583Z","iopub.status.idle":"2024-10-22T07:24:36.413151Z","shell.execute_reply.started":"2024-10-22T07:24:36.412876Z","shell.execute_reply":"2024-10-22T07:24:36.412903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Organize by decades to fit our analysis.\ndf = pd.read_csv('/kaggle/input/arxiv_ai_papers.csv')\n\n# Convert the published date to a datetime format\ndf['published'] = pd.to_datetime(df['published'])\n\n# Extract the year and create a decade column\ndf['year'] = df['published'].dt.year\ndf['decade'] = (df['year'] // 10) * 10\n\n# filter papers from the 1980s\ndf_1980s = df[df['decade'] == 1980]\n\nprint(f\"Printing the database from after 1980\")\nprint(df_1980)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-22T07:24:36.414428Z","iopub.status.idle":"2024-10-22T07:24:36.414970Z","shell.execute_reply.started":"2024-10-22T07:24:36.414697Z","shell.execute_reply":"2024-10-22T07:24:36.414725Z"}},"outputs":[],"execution_count":null}]}