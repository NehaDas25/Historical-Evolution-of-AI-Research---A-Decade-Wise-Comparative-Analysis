{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4fab8a",
   "metadata": {
    "papermill": {
     "duration": 0.0038,
     "end_time": "2024-10-22T18:15:23.477904",
     "exception": false,
     "start_time": "2024-10-22T18:15:23.474104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ“˜ Historical Evolution of AI Research - A Decade-Wise Comparative Analysis\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "This notebook is part of the **Gemini 1.5 Long Context competition**, demonstrating how the model's long context window enables the analysis of a large set of scientific literature spanning decades. The goal is to uncover trends, paradigm shifts, and developments within the field of Artificial Intelligence (AI) by analyzing thousands of research papers, books, and conference proceedings from the 1970s to today.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## ðŸ“ Introduction\r\n",
    "\r\n",
    "The **Gemini 1.5 model**, with its breakthrough large context window of **2 million tokens**, enables the processing of vast amounts of data in a single context. In this project, we leverage this capability to analyze the evolution of scientific literature in AI over the past 50 years. This analysis covers how research trends, terminologies, and paradigms have shifted from one decade to the next, culminating in the current state of the field.\r\n",
    "\r\n",
    "### Why this is important:\r\n",
    "\r\n",
    "- **Rapid Evolution**: Scientific fields evolve rapidly, and understanding the historical context is crucial for predicting future trends.\r\n",
    "- **Trend Analysis**: By analyzing research trends, we can better identify emerging technologies, shifting methodologies, and influential papers that have shaped AI's progress.\r\n",
    "- **Long Context Window**: Gemini's long context window allows us to analyze the entire history of AI research in one continuous process, preserving important contextual connections between papers published across decades."
   ]
  },
  {
   "attachments": {
    "be9caefe-e961-4797-9dbb-b47ef32192e8.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a3d9cfb1",
   "metadata": {
    "papermill": {
     "duration": 0.002886,
     "end_time": "2024-10-22T18:15:23.484112",
     "exception": false,
     "start_time": "2024-10-22T18:15:23.481226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ![arxiv_icon_small.png](attachment:be9caefe-e961-4797-9dbb-b47ef32192e8.png) arXiv Dataset Overview\n",
    "\n",
    "The arXiv dataset provides a comprehensive collection of AI research papers from various categories, including machine learning, robotics, and natural language processing. It covers a wide range of publications spanning multiple decades, offering rich metadata such as titles, abstracts, publication dates, and keywords.\n",
    "\n",
    "### Why this dataset is important:\n",
    "\n",
    "- **Historical Depth**: By covering research papers from the 1970s to the present, the dataset allows for a longitudinal study of AI's evolution.\n",
    "- **Rich Metadata**: The inclusion of detailed abstracts, keywords, and publication years enables a deep dive into trends and paradigm shifts in the field.\n",
    "- **Aligned with Gemini's Capabilities**: The structure of the dataset perfectly aligns with Geminiâ€™s ability to process large context windows, allowing us to analyze the entire body of work continuously and preserve contextual connections over decades.\n",
    "\n",
    "This dataset is essential for uncovering emerging technologies, influential research works, and understanding the trajectory of AI as a field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc61228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T18:15:23.491482Z",
     "iopub.status.busy": "2024-10-22T18:15:23.491166Z",
     "iopub.status.idle": "2024-10-22T18:15:38.627747Z",
     "shell.execute_reply": "2024-10-22T18:15:38.626583Z"
    },
    "papermill": {
     "duration": 15.143042,
     "end_time": "2024-10-22T18:15:38.630293",
     "exception": false,
     "start_time": "2024-10-22T18:15:23.487251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\r\n",
      "  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\r\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: requests~=2.32.0 in /opt/conda/lib/python3.10/site-packages (from arxiv) (2.32.3)\r\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\r\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (2024.8.30)\r\n",
      "Downloading arxiv-2.1.3-py3-none-any.whl (11 kB)\r\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\r\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=934e6d711d02a083866ac295e7e36ef2506d2043873d950b85e622c06322b0aa\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\r\n",
      "Successfully built sgmllib3k\r\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\r\n",
      "Successfully installed arxiv-2.1.3 feedparser-6.0.11 sgmllib3k-1.0.0\r\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import arxiv\n",
    "    print(\"arxiv is already installed.\")\n",
    "except ImportError:\n",
    "    # If arxiv is not installed, install it\n",
    "    !pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277444bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T18:15:38.640532Z",
     "iopub.status.busy": "2024-10-22T18:15:38.640173Z",
     "iopub.status.idle": "2024-10-22T18:15:39.472725Z",
     "shell.execute_reply": "2024-10-22T18:15:39.471774Z"
    },
    "papermill": {
     "duration": 0.840116,
     "end_time": "2024-10-22T18:15:39.474990",
     "exception": false,
     "start_time": "2024-10-22T18:15:38.634874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import all necessary libraries here.\n",
    "import arxiv\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67af964",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T18:15:39.485071Z",
     "iopub.status.busy": "2024-10-22T18:15:39.484662Z",
     "iopub.status.idle": "2024-10-22T18:15:39.489032Z",
     "shell.execute_reply": "2024-10-22T18:15:39.488256Z"
    },
    "papermill": {
     "duration": 0.01127,
     "end_time": "2024-10-22T18:15:39.490908",
     "exception": false,
     "start_time": "2024-10-22T18:15:39.479638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {
    "7ee2cbe6-5c4d-4def-bafa-341ffb8e6423.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b86af7fe",
   "metadata": {
    "papermill": {
     "duration": 0.003899,
     "end_time": "2024-10-22T18:15:39.498868",
     "exception": false,
     "start_time": "2024-10-22T18:15:39.494969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ðŸ“Š Dataset Overview\n",
    "The dataset used in this analysis contains a comprehensive collection of AI research papers spanning over 50 years. Sourced from arXiv.org and NeurIPS conference proceedings, it includes metadata such as titles, authors, abstracts, publication dates, and key terms. This structured information allows us to analyze the evolution of AI research and track paradigm shifts within the field.\n",
    "\n",
    "### Why this dataset is valuable:\n",
    "- **Comprehensive Coverage**: The dataset spans multiple decades, capturing the progression of AI research from its early stages to the present.\n",
    "- **Insightful Metadata**: With detailed abstracts, keywords, and publication dates, the dataset provides rich context for understanding research trends and identifying influential papers.\n",
    "- **Enabling Long-Context Analysis**: The structured data aligns perfectly with Gemini's capability to handle large context windows, enabling a holistic view of AI's development and preserving connections across decades of research.\n",
    "\n",
    "This dataset is essential for identifying patterns, understanding the evolution of terminology, and uncovering the emerging technologies that shape the future of AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a329809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T18:15:39.509131Z",
     "iopub.status.busy": "2024-10-22T18:15:39.508835Z",
     "iopub.status.idle": "2024-10-22T18:50:50.124675Z",
     "shell.execute_reply": "2024-10-22T18:50:50.123655Z"
    },
    "papermill": {
     "duration": 2110.626429,
     "end_time": "2024-10-22T18:50:50.130346",
     "exception": false,
     "start_time": "2024-10-22T18:15:39.503917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers retrieved: 50000\n"
     ]
    }
   ],
   "source": [
    "# Query for AI-related papers from the arXiv API\n",
    "search_query = 'cat:cs.AI OR cat:stat.ML OR cat:cs.LG'\n",
    "\n",
    "# Initialize an empty list to store papers\n",
    "papers = []\n",
    "total_results = 50000  # Total number of results you want to retrieve\n",
    "batch_size = 100  # The maximum batch size supported by arXiv API\n",
    "current_count = 0\n",
    "\n",
    "# Fetch results in batches\n",
    "for start in range(0, total_results, batch_size):\n",
    "    search = arxiv.Search(\n",
    "        query=search_query,\n",
    "        max_results=batch_size,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Fetch results from the search object\n",
    "        for result in search.results():\n",
    "            papers.append({\n",
    "                'title': result.title,\n",
    "                'authors': [author.name for author in result.authors],\n",
    "                'abstract': result.summary,\n",
    "                'published': result.published,\n",
    "                'categories': result.categories,\n",
    "                'pdf_url': result.pdf_url\n",
    "            })\n",
    "            current_count += 1\n",
    "            if current_count >= total_results:\n",
    "                break\n",
    "        time.sleep(3)  \n",
    "    except arxiv.UnexpectedEmptyPageError as e:\n",
    "        print(f\"Empty page encountered at start={start}. Skipping this batch.\")\n",
    "        continue \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break\n",
    "\n",
    "# Display the total number of papers retrieved and the first few entries\n",
    "print(f\"Total papers retrieved: {len(papers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564ad3cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T18:50:50.140129Z",
     "iopub.status.busy": "2024-10-22T18:50:50.139765Z",
     "iopub.status.idle": "2024-10-22T18:50:53.746079Z",
     "shell.execute_reply": "2024-10-22T18:50:53.745281Z"
    },
    "papermill": {
     "duration": 3.61362,
     "end_time": "2024-10-22T18:50:53.748256",
     "exception": false,
     "start_time": "2024-10-22T18:50:50.134636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# After fetching the papers, save the metadata to a CSV file for easier use in Kaggle working directory (/kaggle/working)\n",
    "df = pd.DataFrame(papers)\n",
    "df.to_csv('/kaggle/working/arxiv_ai_papers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be659c2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T18:50:53.758439Z",
     "iopub.status.busy": "2024-10-22T18:50:53.758155Z",
     "iopub.status.idle": "2024-10-22T18:50:54.451800Z",
     "shell.execute_reply": "2024-10-22T18:50:54.450863Z"
    },
    "papermill": {
     "duration": 0.700947,
     "end_time": "2024-10-22T18:50:54.453781",
     "exception": false,
     "start_time": "2024-10-22T18:50:53.752834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers per decade:\n",
      "decade\n",
      "2020    50000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>published</th>\n",
       "      <th>categories</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>year</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reflection-Bench: probing AI intelligence with...</td>\n",
       "      <td>['Lingyu Li', 'Yixu Wang', 'Haiquan Zhao', 'Sh...</td>\n",
       "      <td>The ability to adapt beliefs or behaviors in r...</td>\n",
       "      <td>2024-10-21 17:59:50+00:00</td>\n",
       "      <td>['cs.AI']</td>\n",
       "      <td>http://arxiv.org/pdf/2410.16270v1</td>\n",
       "      <td>2024</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xGen-MM-Vid (BLIP-3-Video): You Only Need 32 T...</td>\n",
       "      <td>['Michael S. Ryoo', 'Honglu Zhou', 'Shrikant K...</td>\n",
       "      <td>We present xGen-MM-Vid (BLIP-3-Video): a multi...</td>\n",
       "      <td>2024-10-21 17:59:11+00:00</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG']</td>\n",
       "      <td>http://arxiv.org/pdf/2410.16267v1</td>\n",
       "      <td>2024</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3DGS-Enhancer: Enhancing Unbounded 3D Gaussian...</td>\n",
       "      <td>['Xi Liu', 'Chaoyi Zhou', 'Siyu Huang']</td>\n",
       "      <td>Novel-view synthesis aims to generate novel vi...</td>\n",
       "      <td>2024-10-21 17:59:09+00:00</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "      <td>http://arxiv.org/pdf/2410.16266v1</td>\n",
       "      <td>2024</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CompassJudger-1: All-in-one Judge Model Helps ...</td>\n",
       "      <td>['Maosong Cao', 'Alexander Lam', 'Haodong Duan...</td>\n",
       "      <td>Efficient and accurate evaluation is crucial f...</td>\n",
       "      <td>2024-10-21 17:56:51+00:00</td>\n",
       "      <td>['cs.CL', 'cs.AI']</td>\n",
       "      <td>http://arxiv.org/pdf/2410.16256v1</td>\n",
       "      <td>2024</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Revisiting Deep Feature Reconstruction for Log...</td>\n",
       "      <td>['Sukanya Patra', 'Souhaib Ben Taieb']</td>\n",
       "      <td>Industrial anomaly detection is crucial for qu...</td>\n",
       "      <td>2024-10-21 17:56:47+00:00</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "      <td>http://arxiv.org/pdf/2410.16255v1</td>\n",
       "      <td>2024</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Distribution Learning with Valid Outputs Beyon...</td>\n",
       "      <td>['Nick Rittler', 'Kamalika Chaudhuri']</td>\n",
       "      <td>Generative models at times produce \"invalid\" o...</td>\n",
       "      <td>2024-10-21 17:56:09+00:00</td>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>http://arxiv.org/pdf/2410.16253v1</td>\n",
       "      <td>2024</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Implicit Regularization for Tubal Tensor Facto...</td>\n",
       "      <td>['Santhosh Karnik', 'Anna Veselovska', 'Mark I...</td>\n",
       "      <td>We provide a rigorous analysis of implicit reg...</td>\n",
       "      <td>2024-10-21 17:52:01+00:00</td>\n",
       "      <td>['cs.LG', 'math.OC', 'math.ST', 'stat.ML', 'st...</td>\n",
       "      <td>http://arxiv.org/pdf/2410.16247v1</td>\n",
       "      <td>2024</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MoRE: Multi-Modal Contrastive Pre-training wit...</td>\n",
       "      <td>['Samrajya Thapa', 'Koushik Howlader', 'Subhan...</td>\n",
       "      <td>In this paper, we introduce a novel Multi-Moda...</td>\n",
       "      <td>2024-10-21 17:42:41+00:00</td>\n",
       "      <td>['cs.AI', 'cs.CV', 'cs.LG']</td>\n",
       "      <td>http://arxiv.org/pdf/2410.16239v1</td>\n",
       "      <td>2024</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sketch2Code: Evaluating Vision-Language Models...</td>\n",
       "      <td>['Ryan Li', 'Yanzhe Zhang', 'Diyi Yang']</td>\n",
       "      <td>Sketches are a natural and accessible medium f...</td>\n",
       "      <td>2024-10-21 17:39:49+00:00</td>\n",
       "      <td>['cs.CL', 'cs.AI']</td>\n",
       "      <td>http://arxiv.org/pdf/2410.16232v1</td>\n",
       "      <td>2024</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Realistic Threat Model for Large Language Mo...</td>\n",
       "      <td>['Valentyn Boreiko', 'Alexander Panfilov', 'Va...</td>\n",
       "      <td>A plethora of jailbreaking attacks have been p...</td>\n",
       "      <td>2024-10-21 17:27:01+00:00</td>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>http://arxiv.org/pdf/2410.16222v1</td>\n",
       "      <td>2024</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Reflection-Bench: probing AI intelligence with...   \n",
       "1  xGen-MM-Vid (BLIP-3-Video): You Only Need 32 T...   \n",
       "2  3DGS-Enhancer: Enhancing Unbounded 3D Gaussian...   \n",
       "3  CompassJudger-1: All-in-one Judge Model Helps ...   \n",
       "4  Revisiting Deep Feature Reconstruction for Log...   \n",
       "5  Distribution Learning with Valid Outputs Beyon...   \n",
       "6  Implicit Regularization for Tubal Tensor Facto...   \n",
       "7  MoRE: Multi-Modal Contrastive Pre-training wit...   \n",
       "8  Sketch2Code: Evaluating Vision-Language Models...   \n",
       "9  A Realistic Threat Model for Large Language Mo...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  ['Lingyu Li', 'Yixu Wang', 'Haiquan Zhao', 'Sh...   \n",
       "1  ['Michael S. Ryoo', 'Honglu Zhou', 'Shrikant K...   \n",
       "2            ['Xi Liu', 'Chaoyi Zhou', 'Siyu Huang']   \n",
       "3  ['Maosong Cao', 'Alexander Lam', 'Haodong Duan...   \n",
       "4             ['Sukanya Patra', 'Souhaib Ben Taieb']   \n",
       "5             ['Nick Rittler', 'Kamalika Chaudhuri']   \n",
       "6  ['Santhosh Karnik', 'Anna Veselovska', 'Mark I...   \n",
       "7  ['Samrajya Thapa', 'Koushik Howlader', 'Subhan...   \n",
       "8           ['Ryan Li', 'Yanzhe Zhang', 'Diyi Yang']   \n",
       "9  ['Valentyn Boreiko', 'Alexander Panfilov', 'Va...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The ability to adapt beliefs or behaviors in r...   \n",
       "1  We present xGen-MM-Vid (BLIP-3-Video): a multi...   \n",
       "2  Novel-view synthesis aims to generate novel vi...   \n",
       "3  Efficient and accurate evaluation is crucial f...   \n",
       "4  Industrial anomaly detection is crucial for qu...   \n",
       "5  Generative models at times produce \"invalid\" o...   \n",
       "6  We provide a rigorous analysis of implicit reg...   \n",
       "7  In this paper, we introduce a novel Multi-Moda...   \n",
       "8  Sketches are a natural and accessible medium f...   \n",
       "9  A plethora of jailbreaking attacks have been p...   \n",
       "\n",
       "                  published  \\\n",
       "0 2024-10-21 17:59:50+00:00   \n",
       "1 2024-10-21 17:59:11+00:00   \n",
       "2 2024-10-21 17:59:09+00:00   \n",
       "3 2024-10-21 17:56:51+00:00   \n",
       "4 2024-10-21 17:56:47+00:00   \n",
       "5 2024-10-21 17:56:09+00:00   \n",
       "6 2024-10-21 17:52:01+00:00   \n",
       "7 2024-10-21 17:42:41+00:00   \n",
       "8 2024-10-21 17:39:49+00:00   \n",
       "9 2024-10-21 17:27:01+00:00   \n",
       "\n",
       "                                          categories  \\\n",
       "0                                          ['cs.AI']   \n",
       "1               ['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG']   \n",
       "2                                 ['cs.CV', 'cs.AI']   \n",
       "3                                 ['cs.CL', 'cs.AI']   \n",
       "4                                 ['cs.CV', 'cs.LG']   \n",
       "5                                          ['cs.LG']   \n",
       "6  ['cs.LG', 'math.OC', 'math.ST', 'stat.ML', 'st...   \n",
       "7                        ['cs.AI', 'cs.CV', 'cs.LG']   \n",
       "8                                 ['cs.CL', 'cs.AI']   \n",
       "9                                          ['cs.LG']   \n",
       "\n",
       "                             pdf_url  year  decade  \n",
       "0  http://arxiv.org/pdf/2410.16270v1  2024    2020  \n",
       "1  http://arxiv.org/pdf/2410.16267v1  2024    2020  \n",
       "2  http://arxiv.org/pdf/2410.16266v1  2024    2020  \n",
       "3  http://arxiv.org/pdf/2410.16256v1  2024    2020  \n",
       "4  http://arxiv.org/pdf/2410.16255v1  2024    2020  \n",
       "5  http://arxiv.org/pdf/2410.16253v1  2024    2020  \n",
       "6  http://arxiv.org/pdf/2410.16247v1  2024    2020  \n",
       "7  http://arxiv.org/pdf/2410.16239v1  2024    2020  \n",
       "8  http://arxiv.org/pdf/2410.16232v1  2024    2020  \n",
       "9  http://arxiv.org/pdf/2410.16222v1  2024    2020  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Organize by decades to fit our analysis.\n",
    "df = pd.read_csv('/kaggle/working/arxiv_ai_papers.csv')\n",
    "\n",
    "# Convert the published date to a datetime format\n",
    "df['published'] = pd.to_datetime(df['published'])\n",
    "\n",
    "# Extract the year and create a decade column\n",
    "df['year'] = df['published'].dt.year\n",
    "df['decade'] = (df['year'] // 10) * 10\n",
    "\n",
    "# Group the data by decades and count the number of entries in each decade\n",
    "decade_counts = df['decade'].value_counts().sort_index()\n",
    "\n",
    "# Display the counts for each decade\n",
    "print(\"Number of papers per decade:\")\n",
    "print(decade_counts)\n",
    "\n",
    "# Filter papers starting from the 1990s\n",
    "df_1990s_and_later = df[df['decade'] >= 1990]\n",
    "\n",
    "display(df_1990s_and_later.head(10))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9881586,
     "sourceId": 83735,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2134.201377,
   "end_time": "2024-10-22T18:50:54.977663",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-22T18:15:20.776286",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
