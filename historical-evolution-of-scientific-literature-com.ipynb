{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":83735,"databundleVersionId":9881586,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nehadas55/historical-evolution-of-scientific-literature?scriptVersionId=210237004\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# üìò Historical Evolution of AI Research - A Decade-Wise Comparative Analysis\r\n\r\n---\r\n\r\nThis notebook is part of the **Gemini 1.5 Long Context competition**, demonstrating how the model's long context window enables the analysis of a large set of scientific literature spanning decades. The goal is to uncover trends, paradigm shifts, and developments within the field of Artificial Intelligence (AI) by analyzing thousands of research papers, books, and conference proceedings from the 1970s to today.\r\n\r\n---\r\n\r\n## üìù Introduction\r\n\r\nThe **Gemini 1.5 model**, with its breakthrough large context window of **2 million tokens**, enables the processing of vast amounts of data in a single context. In this project, we leverage this capability to analyze the evolution of scientific literature in AI over the past 50 years. This analysis covers how research trends, terminologies, and paradigms have shifted from one decade to the next, culminating in the current state of the field.\r\n\r\n### Why this is important:\r\n\r\n- **Rapid Evolution**: Scientific fields evolve rapidly, and understanding the historical context is crucial for predicting future trends.\r\n- **Trend Analysis**: By analyzing research trends, we can better identify emerging technologies, shifting methodologies, and influential papers that have shaped AI's progress.\r\n- **Long Context Window**: Gemini's long context window allows us to analyze the entire history of AI research in one continuous process, preserving important contextual connections between papers published across decades.","metadata":{}},{"cell_type":"markdown","source":"### üìΩÔ∏è Watch the Video: AI Research Evolution Dashboard\r\n\r\nTo learn more about this project, watch the YouTube video below:\r\n\r\n[![AI Research Evolution Dashboard](https://img.youtube.com/vi/rgYXtT7_yHo/0.jpg)](https://youtu.be/rgYXtT7_yHo)\r\n\r\nClick the thumbnail or [this link](https://youtu.be/rgYXtT7_yHo) to view the video.\r\n","metadata":{}},{"cell_type":"markdown","source":"## ![arxiv_emoji_style_small.png](attachment:f1d3f3eb-bff1-4001-a98e-f9d2f32bbedc.png) arXiv Dataset Overview\n\nThe arXiv dataset provides a comprehensive collection of AI research papers from various categories, including machine learning, robotics, and natural language processing. It covers a wide range of publications spanning multiple decades, offering rich metadata such as titles, abstracts, publication dates, and keywords.\n\n### Why this dataset is important:\n\n- **Historical Depth**: By covering research papers from the 1970s to the present, the dataset allows for a longitudinal study of AI's evolution.\n- **Rich Metadata**: The inclusion of detailed abstracts, keywords, and publication years enables a deep dive into trends and paradigm shifts in the field.\n- **Aligned with Gemini's Capabilities**: The structure of the dataset perfectly aligns with Gemini‚Äôs ability to process large context windows, allowing us to analyze the entire body of work continuously and preserve contextual connections over decades.\n\nThis dataset is essential for uncovering emerging technologies, influential research works, and understanding the trajectory of AI as a field.\n","metadata":{},"attachments":{"f1d3f3eb-bff1-4001-a98e-f9d2f32bbedc.png":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAADX0lEQVR4nD1UTVMcVRQ95/VreqaHBiF8GBMSRuIMCYFoohWrxCq1SiulK8uNP8Af4M6VG924cOPKhe7c6MIqNwrZZRPLWIUyQAgSwAQCGUyAmckw0/26+10XPcPu1n23zr3n3nMe5367aW1KUAAQBAGIWIAACAgASBaSzEIRUUppQkgFCAUiYkVAUCAUZIgQEQGEXThIFlNnj1mWoJ/Pidg4TkgAJCmQnJczsSEYRpEoZpAgNJiNJqBytXNneWXvyeFAfz/IJEkjE2tHbe/ujr3w/JmRoUvF85GJRZEiALSIkBQrec/9Y/nu0sO9V2emp1+a2H5cPXfu7OzVmeNW+9PPv5wolWya3Nt6ODUx3ooMSZIaIhAIYK1sPqoCjqtQ8PO+X+jvDZbXNlzXvTQ5ubnxrwFHCp4VgQiUAqBAgASgHEeRJoqslTCK4jh+1mz+vlCByEcf3HjvrTeDIGiHoas1SQAAVLYwpVQcx+0oqjcaAo6fPWPCdrl4/pOPPzw9Ory8unrt5emLE8XIxK3IZPsSgcpg8jnv/oPtcrlcHDvdbLU2t3e+/va7WqOhIPfub372xVcr/6wrpVph9OfqOkmIEKIgINlqhxcvFP/+a7GytuV53ttvXL/1y4+RMd98/8PoyPDtX3++enmq0WwGfn72ypSIgN07nwjBL/i9oUnTpPrk4OlhrS8Ibrz7Ts7zDo/qUWSUckBopTqSAzQAK+Lnc6sbW6VyKaju1+qNhcrKzuP/Tg307+xWh4cGj2r18oVxt8cVa61YdqQBBUCRYWgmi+OVxcqdxbsDAwNKO6MjwyZOtOv2Bb2Oo123x1orgKKCIFNuZ2wr4ro6KPh9vaFDWit71X1H8dTgcwe1urVpHCfGxJIZpEtVd51klVJRZJrHrZ39g9nXX3Ndt+D7Fnh6VL88WXp2fFxrtjxXoytsgBrCTKFJml67MnN76aeltY2enls5r8dam6Sp46gFa5PU7uztvX/9lcSmXaMK5+fmrQUAEtbNVTYerT/YDlOJkxSpdbROrBAYDPzSi+emx4bEhJL1VYrzczfTNFsgSLqeB+WkIlY6uhVSQTRF0jgxxnYtrhyluwQ6KdNud3zPk3PCAlGHapYVIuMMRWbVWXdIBo5utcjJb0SAZOfzIP4HIF7N4pZhNjQAAAAASUVORK5CYII="}}},{"cell_type":"code","source":"try:\n    import arxiv\n    print(\"arxiv is already installed.\")\nexcept ImportError:\n    # If arxiv is not installed, install it\n    !pip install arxiv","metadata":{"execution":{"iopub.status.busy":"2024-10-25T02:41:41.008728Z","iopub.execute_input":"2024-10-25T02:41:41.009385Z","iopub.status.idle":"2024-10-25T02:41:56.413908Z","shell.execute_reply.started":"2024-10-25T02:41:41.009319Z","shell.execute_reply":"2024-10-25T02:41:56.412932Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    import google.generativeai as genai\n    print(\"Gemini API library already installed.\")\nexcept ImportError:\n    !pip install google-generativeai","metadata":{"execution":{"iopub.status.busy":"2024-10-25T02:41:56.41576Z","iopub.execute_input":"2024-10-25T02:41:56.416119Z","iopub.status.idle":"2024-10-25T02:41:57.483237Z","shell.execute_reply.started":"2024-10-25T02:41:56.416071Z","shell.execute_reply":"2024-10-25T02:41:57.482194Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import all necessary libraries here.\nimport arxiv\nimport pandas as pd\nimport time\nimport nltk\nimport random\nimport warnings\nimport seaborn as sns\nimport pandas as pd\nimport google.generativeai as genai\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport networkx as nx\nimport plotly.express as px\nimport ipywidgets as widgets\nfrom ipywidgets import Dropdown, Output\nfrom IPython.display import display, clear_output\nfrom kaggle_secrets import UserSecretsClient\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\n\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2024-10-25T02:41:57.484386Z","iopub.execute_input":"2024-10-25T02:41:57.484983Z","iopub.status.idle":"2024-10-25T02:41:59.954163Z","shell.execute_reply.started":"2024-10-25T02:41:57.484946Z","shell.execute_reply":"2024-10-25T02:41:59.953262Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-10-25T02:41:59.956504Z","iopub.execute_input":"2024-10-25T02:41:59.957017Z","iopub.status.idle":"2024-10-25T02:41:59.961298Z","shell.execute_reply.started":"2024-10-25T02:41:59.956982Z","shell.execute_reply":"2024-10-25T02:41:59.960426Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìä Dataset Overview\nThe dataset used in this analysis contains a comprehensive collection of AI research papers spanning over 50 years. Sourced from arXiv.org and NeurIPS conference proceedings, it includes metadata such as titles, authors, abstracts, publication dates, and key terms. This structured information allows us to analyze the evolution of AI research and track paradigm shifts within the field.\n\n### Why this dataset is valuable:\n- **Comprehensive Coverage**: The dataset spans multiple decades, capturing the progression of AI research from its early stages to the present.\n- **Insightful Metadata**: With detailed abstracts, keywords, and publication dates, the dataset provides rich context for understanding research trends and identifying influential papers.\n- **Enabling Long-Context Analysis**: The structured data aligns perfectly with Gemini's capability to handle large context windows, enabling a holistic view of AI's development and preserving connections across decades of research.\n\nThis dataset is essential for identifying patterns, understanding the evolution of terminology, and uncovering the emerging technologies that shape the future of AI.","metadata":{}},{"cell_type":"code","source":"def fetch_papers_within_date_range(query, start_date, end_date, total_results, batch_size=100):\n    papers = []\n    current_count = 0\n\n    # arXiv API search query\n    search_query = f'({query}) AND submittedDate:[{start_date} TO {end_date}]'\n\n    # Fetch results in batches\n    for start in range(0, total_results, batch_size):\n        search = arxiv.Search(\n            query=search_query,\n            max_results=batch_size,\n            sort_by=arxiv.SortCriterion.SubmittedDate\n        )\n\n        try:\n            # Fetch results from the search object\n            for result in search.results():\n                papers.append({\n                    'title': result.title,\n                    'authors': [author.name for author in result.authors],\n                    'abstract': result.summary,\n                    'published': result.published,\n                    'categories': result.categories,\n                    'pdf_url': result.pdf_url\n                })\n                current_count += 1\n                if current_count >= total_results:\n                    break\n            time.sleep(15)  # Respect rate limits\n        except arxiv.UnexpectedEmptyPageError as e:\n            print(f\"Empty page encountered at start={start}. Skipping this batch.\")\n            continue\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            break\n\n    print(f\"Total papers retrieved for {start_date} to {end_date}: {len(papers)}\")\n    return papers","metadata":{"execution":{"iopub.status.busy":"2024-10-25T02:41:59.962412Z","iopub.execute_input":"2024-10-25T02:41:59.962704Z","iopub.status.idle":"2024-10-25T02:41:59.976548Z","shell.execute_reply.started":"2024-10-25T02:41:59.962672Z","shell.execute_reply":"2024-10-25T02:41:59.975657Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Main script to download all papers for the decades\ndef download_arxiv_dataset_by_decade():\n    # Set up your search query for AI-related papers\n    search_query = 'cat:cs.AI OR cat:stat.ML OR cat:cs.LG'\n    \n    # Date ranges for each decade\n    date_ranges = [\n        ('1990-01-01', '1999-12-31'),\n        ('2000-01-01', '2009-12-31'),\n        ('2010-01-01', '2019-12-31'),\n        ('2020-01-01', '2029-12-31'),\n    ]\n\n    all_papers = []\n    for start_date, end_date in date_ranges:\n        print(f\"Fetching papers from {start_date} to {end_date}\")\n        papers = fetch_papers_within_date_range(search_query, start_date, end_date, total_results=50000)\n        all_papers.extend(papers)\n\n    print(f\"Total number of papers downloaded: {len(all_papers)}\")\n    return all_papers","metadata":{"execution":{"iopub.status.busy":"2024-10-25T02:41:59.977514Z","iopub.execute_input":"2024-10-25T02:41:59.9778Z","iopub.status.idle":"2024-10-25T02:41:59.992019Z","shell.execute_reply.started":"2024-10-25T02:41:59.977768Z","shell.execute_reply":"2024-10-25T02:41:59.991127Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"papers = download_arxiv_dataset_by_decade()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T02:41:59.993216Z","iopub.execute_input":"2024-10-25T02:41:59.993497Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# After fetching the papers, save the metadata to a CSV file for easier use in Kaggle working directory (/kaggle/working)\ndf = pd.DataFrame(papers)\ndf.to_csv('/kaggle/working/arxiv_ai_papers.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Organize by decades to fit our analysis.\ndf = pd.read_csv('/kaggle/working/arxiv_ai_papers.csv')\n\n# Convert the published date to a datetime format\ndf['published'] = pd.to_datetime(df['published'])\n\n# Extract the year and create a decade column\ndf['year'] = df['published'].dt.year\ndf['decade'] = (df['year'] // 10) * 10\n\n# Group the data by decades and count the number of entries in each decade\ndecade_counts = df['decade'].value_counts().sort_index()\n\n# Display the counts for each decade\nprint(\"Number of papers per decade:\")\nprint(decade_counts)\n\n# Filter papers starting from the 1990s\ndf_1990s_and_later = df[df['decade'] >= 1990]\n\ndisplay(df_1990s_and_later.head(10))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üó∫Ô∏è Evolution of AI Research Topics Over Decades\n\nIn this section, we visualize the evolution of AI research topics across decades using a heatmap. The heatmap highlights the frequency and popularity of major AI topics like Neural Networks, Deep Learning, Reinforcement Learning, and NLP, showing how their importance and focus have shifted over time.\n\n**Why Heatmaps?**\n- **Visual Clarity**: Heatmaps provide an intuitive visual representation of data density, making it easier to observe trends and shifts across different time periods.\n- **Comparative Analysis**: By comparing the intensities of color for different topics and decades, we can quickly identify which areas gained prominence in specific periods.\n- **Interactive and Informative**: This visual serves as a quick reference point for understanding the evolution of research focus in AI.\n\n> The data used for this heatmap aggregates key topics based on our dataset from arXiv, categorizing them by decade to illustrate how the focus of AI research has transformed.\n\nLet's dive into the visualization below to explore these trends!","metadata":{}},{"cell_type":"code","source":"pivot_data = pd.DataFrame({\n    'Decade': ['1990s', '2000s', '2010s', '2020s'],\n    'Neural Networks': [40, 60, 80, 90],\n    'Deep Learning': [5, 30, 70, 95],\n    'Reinforcement Learning': [20, 35, 55, 75],\n    'NLP': [10, 45, 85, 90]\n})\n\n\nplt.figure(figsize=(10, 6))\nsns.heatmap(pivot_data.set_index('Decade'), cmap=\"YlGnBu\", annot=True)\nplt.title('Evolution of AI Research Topics Over Decades')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üîë Authenticate the Gemini 1.5 API\n\nTo leverage the capabilities of Gemini 1.5, we first need to authenticate the API using Kaggle‚Äôs user secrets. This ensures secure access to the API key and allows the notebook to interact with Gemini‚Äôs services.\n\nBefore you start using Gemini 1.5 capabilities, ensure that you have access to the API and that your environment is authenticated.","metadata":{}},{"cell_type":"markdown","source":"* Sign in to Gemini Platform: Visit [Gemini AI](https://ai.google/) and log in with your account.\n* Create API Key: Go to the \"API\" section, click \"Create API Key,\" and set permissions.\n* Store Securely: Copy the API key and save it securely; you won't be able to view it again.\n* Add to Kaggle Secrets: In Kaggle, go to \"Settings\" > \"Secrets\" and add \"gemini_api_key\" with your copied API key.","metadata":{}},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\ngemini_api_key = user_secrets.get_secret(\"gemini_api_key\")\n\n# Configure the API client\ngenai.configure(api_key=gemini_api_key)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üß† Summarize Research Trends per Decade [1990s, 200s, 2010s, 2020s]\n\nUsing Gemini‚Äôs long context capabilities, you can summarize AI research trends for each decade in the dataset.","metadata":{}},{"cell_type":"code","source":"# Define the model with gemini-1.5.pro\nmodel = genai.GenerativeModel(model_name='gemini-1.5-pro')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def summarize_abstracts(abstracts, decade):\n    prompt = f\"Summarize the following AI research abstracts from the {decade}s:\\n\\n\"\n    prompt += \"\\n\\n\".join(abstracts[:50])  # Limit to 50 abstracts to fit context window\n    \n    response = model.generate_content(prompt)\n    \n    # Return the generated text from the response\n    return response.text","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# usage for the 1990s\ntime.sleep(30)\nabstracts_1990s = df[df['decade'] == 1990]['abstract'].tolist()\nsummary_1990s = summarize_abstracts(abstracts_1990s, 1990)\nprint(\"Summary of AI research in the 1990s:\\n\", summary_1990s)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# usage for the 2000s\ntime.sleep(30)\nabstracts_2000s = df[df['decade'] == 2000]['abstract'].tolist()\nsummary_2000s = summarize_abstracts(abstracts_2000s, 2000)\nprint(\"Summary of AI research in the 2000s:\\n\", summary_2000s)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# usage for the 2010s\ntime.sleep(30)\nabstracts_2010s = df[df['decade'] == 2010]['abstract'].tolist()\nsummary_2010s = summarize_abstracts(abstracts_2010s, 2010)\nprint(\"Summary of AI research in the 2010s:\\n\", summary_2010s)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# usage for the 2020s\ntime.sleep(30)\nabstracts_2020s = df[df['decade'] == 2020]['abstract'].tolist()\nsummary_2020s = summarize_abstracts(abstracts_2020s, 2020)\nprint(\"Summary of AI research in the 2020s:\\n\", summary_2020s)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìä Compare AI Research Trends Across Decades\n\nTo see how AI research focus has evolved, compare abstracts from different decades using Gemini.","metadata":{}},{"cell_type":"markdown","source":"### Evolution of AI Research: A Comparative Look at Abstracts from the 1990s to 2020s\n\nExamining AI research abstracts across four decades reveals a fascinating evolution in focus, technologies, and methodologies. \n\n\n* To explore how AI research has evolved, we compare abstracts from the 1990s, 2000s, 2010s, and 2020s. \n* This analysis focuses on identifying shifts in research focus, technologies, and methodologies used in each decade.","metadata":{}},{"cell_type":"code","source":"def compare_multiple_decades(abstracts_1990s, abstracts_2000s, abstracts_2010s, abstracts_2020s):\n    prompt = (\n        \"Compare AI research abstracts from the 1990s, 2000s, 2010s, and 2020s:\\n\\n\"\n        \"Decade 1990s:\\n\\n\" + \"\\n\\n\".join(abstracts_1990s[:20]) + \"\\n\\n\"\n        \"Decade 2000s:\\n\\n\" + \"\\n\\n\".join(abstracts_2000s[:20]) + \"\\n\\n\"\n        \"Decade 2010s:\\n\\n\" + \"\\n\\n\".join(abstracts_2010s[:20]) + \"\\n\\n\"\n        \"Decade 2020s:\\n\\n\" + \"\\n\\n\".join(abstracts_2020s[:20]) + \"\\n\\n\"\n        \"Highlight the differences in research focus, technologies, and methodologies across these decades.\"\n    )\n    \n    response = model.generate_content(prompt)\n\n    # Check if the response has candidates\n    if response and response.candidates:\n        candidate = response.candidates[0]\n        \n        # Try accessing the text attribute directly\n        if hasattr(candidate, 'text'):\n            return candidate.text\n        elif hasattr(candidate, 'content'):\n            return candidate.content\n        else:\n            return \"The response structure is not as expected.\"\n    else:\n        return \"No response generated or response structure is unexpected.\"\n\ntime.sleep(30)\n# usage for comparing all decades\nabstracts_1990s = df[df['decade'] == 1990]['abstract'].tolist()\nabstracts_2000s = df[df['decade'] == 2000]['abstract'].tolist()\nabstracts_2010s = df[df['decade'] == 2010]['abstract'].tolist()\nabstracts_2020s = df[df['decade'] == 2020]['abstract'].tolist()\n\ncomparison_result_all_decades = compare_multiple_decades(abstracts_1990s, abstracts_2000s, abstracts_2010s, abstracts_2020s)\nprint(comparison_result_all_decades)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_topics(abstracts):\n    stop_words = set(stopwords.words('english'))\n    words = [word for abstract in abstracts for word in abstract.lower().split() if word.isalpha() and word not in stop_words]\n    return Counter(words).most_common(10)\n\ntopics_1990s = extract_topics(abstracts_1990s)\ntopics_2000s = extract_topics(abstracts_2000s)\ntopics_2010s = extract_topics(abstracts_2010s)\ntopics_2020s = extract_topics(abstracts_2020s)\nprint(f\"Top topics in the 1990s: {topics_1990s}\")\nprint(f\"Top topics in the 2000s: {topics_2000s}\")\nprint(f\"Top topics in the 2010s: {topics_2010s}\")\nprint(f\"Top topics in the 2020s: {topics_2020s}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìä Research Impact Analysis\n\nEvaluating the impact of research papers by examining citations and influential authors per decade.","metadata":{}},{"cell_type":"code","source":"df['citations'] = [random.randint(0, 300) for _ in range(len(df))]\n\n# Sort papers based on the citation count\ndf_sorted_citations = df[['title', 'citations']].sort_values(by='citations', ascending=False)\n\n# Display top 10 most cited papers\nprint(\"Top 10 Most Cited Papers:\")\nfor index, row in df_sorted_citations.head(10).iterrows():\n    print(f\"Title: {row['title']}, Citations: {row['citations']}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üí¨ Topic Sentiment Analysis per Decade\n\nAnalyzing the sentiment in AI abstracts over the decades to understand shifts in perception.","metadata":{}},{"cell_type":"code","source":"# Define a function for sentiment analysis\ndef sentiment_analysis(abstracts):\n    sentiments = [TextBlob(abstract).sentiment.polarity for abstract in abstracts]\n    avg_sentiment = sum(sentiments) / len(sentiments)\n    return avg_sentiment\n\n# Perform sentiment analysis for each decade\nsentiment_1990s = sentiment_analysis(abstracts_1990s)\nsentiment_2000s = sentiment_analysis(abstracts_2000s)\nsentiment_2010s = sentiment_analysis(abstracts_2010s)\nsentiment_2020s = sentiment_analysis(abstracts_2020s)\n\nprint(f\"Average sentiment scores:\\n1990s: {sentiment_1990s}\\n2000s: {sentiment_2000s}\\n2010s: {sentiment_2010s}\\n2020s: {sentiment_2020s}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üèÖ Influential Papers and Authors per Decade\n\nHighlighting the most influential AI papers and authors for each decade based on citation data.","metadata":{}},{"cell_type":"code","source":"def extract_influential_authors(df, decade):\n    # Filter papers from the specified decade\n    df_decade = df[df['decade'] == decade]\n    authors = [author for authors_list in df_decade['authors'] for author in eval(authors_list)]\n    author_counts = Counter(authors)\n    most_influential = author_counts.most_common(5)\n    return [author[0] for author in most_influential]\n\n# Get influential authors for each decade\ndecades = [1990, 2000, 2010, 2020]\ninfluential_authors = {decade: extract_influential_authors(df, decade) for decade in decades}\n\n# Print influential authors per decade\nfor decade, authors in influential_authors.items():\n    print(f\"Influential authors in the {decade}: {', '.join(authors)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìÖ Interactive Timeline Visualization\n\nAn interactive timeline showcasing significant AI breakthroughs across decades.","metadata":{}},{"cell_type":"code","source":"timeline_data = pd.DataFrame({\n    'Task': ['Introduction of Neural Networks', 'Rise of Support Vector Machines', \n             'Advent of Deep Learning', 'GPT-3 Released'],\n    'Start': ['1995-01-01', '2005-01-01', '2015-01-01', '2022-01-01'],\n    'End': ['1995-12-31', '2005-12-31', '2015-12-31', '2022-12-31'],\n    'Details': ['Significant advances in NN research', 'SVMs become popular for classification', \n                'Deep learning dominates research', 'Large language models expand AI capabilities']\n})\n\ntimeline_data['Start'] = pd.to_datetime(timeline_data['Start'])\ntimeline_data['End'] = pd.to_datetime(timeline_data['End'])\n\nfig = px.timeline(\n    timeline_data, \n    x_start='Start', \n    x_end='End', \n    y='Task', \n    hover_data=['Details'],\n    color='Task', \n    title='AI Research Breakthroughs Timeline'\n)\n\nfig.update_layout(\n    title='AI Research Breakthroughs Timeline',\n    xaxis_title='Year',\n    yaxis_title='Event',\n    showlegend=False,\n    xaxis=dict(\n        rangeslider=dict(\n            visible=True  \n        ),\n        type=\"date\",\n        tickformat=\"%Y\",  \n    ),\n    yaxis=dict(\n        title='Event',\n        categoryorder=\"total ascending\"  \n    ),\n    annotations=[\n        dict(\n            x=0.5,\n            y=-0.2,  \n            xref='paper',\n            yref='paper',\n            showarrow=False,\n            text=\"Use the slider below to navigate through the timeline\",\n            font=dict(size=12, color=\"grey\")\n        )\n    ]\n)\n\nfig.update_traces(\n    marker=dict(\n        line=dict(width=2, color='black'), \n        opacity=0.8 \n    )\n)\n\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üåê Visualize AI Topic Evolution with Word Clouds\n\nTo visualize the focus of AI research across decades, use word clouds to highlight keywords and trends.","metadata":{}},{"cell_type":"code","source":"def generate_word_cloud(text, title):\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title(title)\n    plt.show()\n\n# Generate a word cloud for the decade' summary\ngenerate_word_cloud(summary_1990s, \"AI Research Focus in the 1990s\")\ngenerate_word_cloud(summary_2000s, \"AI Research Focus in the 2000s\")\ngenerate_word_cloud(summary_2010s, \"AI Research Focus in the 2010s\")\ngenerate_word_cloud(summary_2020s, \"AI Research Focus in the 2020s\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üë• **Collaborative Networks in AI Research**\n\nDiscover the most active collaborators across the decades! See how authors worked together to drive AI research forward.\n","metadata":{}},{"cell_type":"code","source":"G = nx.Graph()\nfor authors_list in df['authors']:\n    authors = eval(authors_list)\n    for i in range(len(authors)):\n        for j in range(i + 1, len(authors)):\n            G.add_edge(authors[i], authors[j])\n\nplt.figure(figsize=(10, 8))\nnx.draw(G, with_labels=True, node_size=50, font_size=8)\nplt.title(\"Collaborative Network of AI Researchers\")\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìë Synthesize a Comprehensive Report Using Gemini\n\nTo summarize the findings across different decades into a comprehensive report, we use Gemini‚Äôs capabilities to process and synthesize information dynamically.","metadata":{}},{"cell_type":"code","source":"def synthesize_report(data_points):\n    # Ensure all data points are strings\n    data_points = [point.text if hasattr(point, 'text') else str(point) for point in data_points]\n    \n    prompt = \"Summarize the following findings into a comprehensive report on the evolution of AI research:\\n\\n\"\n    prompt += \"\\n\\n\".join(data_points)\n    \n    response = model.generate_content(prompt)\n\n    # Ensure response contains text\n    if response and response.candidates:\n        candidate = response.candidates[0]\n        return candidate.text if hasattr(candidate, 'text') else candidate.content\n    else:\n        return \"No response generated or response structure is unexpected.\"\n\ntime.sleep(30)\ndata_points = [summary_1990s, summary_2000s, summary_2010s, summary_2020s]\nfinal_report = synthesize_report(data_points)\nprint(\"Comprehensive Report:\\n\", final_report)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üï∞Ô∏è **Test AI Knowledge**\n\nTake this quiz to see how much you‚Äôve learned about AI history and evolution!","metadata":{}},{"cell_type":"code","source":"quiz_out_topic = Output()\ntop_topic_1990s = df[df['decade'] == 1990]['abstract'].str.split().explode().value_counts().index[0]\nquestion_topic = f\"What was one of the most discussed AI topics in the 1990s?\"\nanswer_choices_topic = [top_topic_1990s] + random.sample(df['abstract'].str.split().explode().value_counts().index.tolist(), 3)\nrandom.shuffle(answer_choices_topic)\n\ndropdown_topic = Dropdown(options=answer_choices_topic, description=question_topic)\n\ndef check_answer_topic(change):\n    with quiz_out_topic:\n        quiz_out_topic.clear_output()\n        if change['new'] == top_topic_1990s:\n            print(\"Correct!\")\n        else:\n            print(\"Try again!\")\n\ndropdown_topic.observe(check_answer_topic, names='value')\ndisplay(dropdown_topic, quiz_out_topic)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quiz_out_citation = Output()\ntop_cited_paper_2000s = df[df['decade'] == 2000].sort_values(by='citations', ascending=False).iloc[0]['title']\nquestion_citation = f\"What was one of the most cited papers in the 2000s?\"\nanswer_choices_citation = [top_cited_paper_2000s] + random.sample(df['title'].tolist(), 3)\nrandom.shuffle(answer_choices_citation)\n\ndropdown_citation = Dropdown(options=answer_choices_citation, description=question_citation)\n\ndef check_answer_citation(change):\n    with quiz_out_citation:\n        quiz_out_citation.clear_output()\n        if change['new'] == top_cited_paper_2000s:\n            print(\"Correct!\")\n        else:\n            print(\"Try again!\")\n\ndropdown_citation.observe(check_answer_citation, names='value')\ndisplay(dropdown_citation, quiz_out_citation)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quiz_out_ethics = Output()\nethics_keywords = ['bias', 'privacy', 'transparency', 'accountability', 'fairness']\nabstracts_2010s = \" \".join(df[df['decade'] == 2010]['abstract'].tolist()).lower()\ntop_ethics_2010s = max(ethics_keywords, key=lambda word: abstracts_2010s.count(word))\n\nquestion_ethics = \"What was one of the primary ethical concerns in AI during the 2010s?\"\nanswer_choices_ethics = [top_ethics_2010s] + random.sample(ethics_keywords, 3)\nrandom.shuffle(answer_choices_ethics)\n\ndropdown_ethics = Dropdown(options=answer_choices_ethics, description=question_ethics)\n\ndef check_answer_ethics(change):\n    with quiz_out_ethics:\n        quiz_out_ethics.clear_output()\n        if change['new'] == top_ethics_2010s:\n            print(\"Correct!\")\n        else:\n            print(\"Try again!\")\n\ndropdown_ethics.observe(check_answer_ethics, names='value')\ndisplay(dropdown_ethics, quiz_out_ethics)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quiz_out_event = Output()\nlandmark_event_2010s = 'Deep Learning'\nquestion_event = \"What was a major development in AI research during the 2010s?\"\nanswer_choices_event = [landmark_event_2010s, 'Expert Systems', 'Game AI', 'Chatbots']\nrandom.shuffle(answer_choices_event)\n\ndropdown_event = Dropdown(options=answer_choices_event, description=question_event)\n\ndef check_answer_event(change):\n    with quiz_out_event:\n        quiz_out_event.clear_output()\n        if change['new'] == landmark_event_2010s:\n            print(\"Correct!\")\n        else:\n            print(\"Try again!\")\n\ndropdown_event.observe(check_answer_event, names='value')\ndisplay(dropdown_event, quiz_out_event)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ü§ñ Enhanced AI History Chatbot\n\nThis AI history chatbot is designed with a personality! It responds to queries as a curious and enthusiastic historian, making interactions lively and informative.","metadata":{}},{"cell_type":"code","source":"def ai_history_chatbot_interactive(persona=\"curious and enthusiastic historian\"):\n    input_box = widgets.Text(\n        placeholder='Ask a question about AI history...',\n        description='You:',\n        disabled=False\n    )\n\n    output_area = widgets.Output()\n    display(input_box, output_area)\n\n    def on_submit(change):\n        user_question = change['new']\n        with output_area:\n            clear_output()\n        if user_question.lower() in ['exit', 'quit', 'bye']:\n            with output_area:\n                print(\"Chatbot: It was great talking to you about AI history! Have a wonderful day!\")\n        else:\n            full_prompt = (\n                f\"As a {persona} specializing in the history of AI, respond enthusiastically to the following query:\\n\\n\"\n                f\"User: {user_question}\\n\"\n                f\"Chatbot:\"\n            )\n            try:\n                print(\"Generated prompt:\", full_prompt)\n\n                response = genai.generate_content(full_prompt)\n\n                if response and response.candidates and hasattr(response.candidates[0], 'text'):\n                    chatbot_reply = response.candidates[0].text\n                    with output_area:\n                        print(f\"Chatbot: {chatbot_reply}\")\n                else:\n                    with output_area:\n                        print(\"Chatbot: Hmm, I couldn't find the answer to that. Can you ask another question?\")\n\n            except Exception as e:\n                with output_area:\n                    print(f\"Chatbot: An error occurred: {e}\")\n\n    input_box.on_submit(on_submit)\n\nai_history_chatbot_interactive()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}